from fastapi import APIRouter, UploadFile, File, HTTPException, Depends, Form
from fastapi.responses import JSONResponse
from typing import Optional, Any, Dict
from pydantic import BaseModel
import tempfile
import os
from datetime import datetime

from ..auth.dependencies import get_current_user
from ..models.user import User
from supabase_integration import supabase
from rag.audio_service import get_audio_service

router = APIRouter(prefix="/api/audio", tags=["audio"])

class TranscripcionRespuesta(BaseModel):
    exito: bool
    texto_transcrito: str
    duracion_audio: float
    idioma_detectado: str
    confianza: float
    timestamp: str

class MensajeAudio(BaseModel):
    session_id: str
    transcripcion: str
    duracion: Optional[float] = None
    idioma: Optional[str] = "es"
    metadata_audio: Dict[str, Any] = {}

class TextoAudio(BaseModel):
    session_id: str
    texto: str
    voz: Optional[str] = "es-ES-Standard-A"
    velocidad: Optional[float] = 1.0

async def obtener_sesion_audio(session_id: str, abogado_id: str) -> Dict:
    """Obtiene una sesi√≥n espec√≠fica verificando que pertenezca al abogado."""
    try:
        response = supabase.table('chat_sesiones')\
            .select('*')\
            .eq('session_id', session_id)\
            .eq('abogado_id', abogado_id)\
            .single()\
            .execute()
        
        if not response.data:
            raise HTTPException(status_code=404, detail="Sesi√≥n no encontrada")
        
        return response.data
    except Exception as e:
        if "No rows found" in str(e):
            raise HTTPException(status_code=404, detail="Sesi√≥n no encontrada")
        raise HTTPException(status_code=500, detail=f"Error obteniendo sesi√≥n: {str(e)}")

@router.post("/transcribir", response_model=TranscripcionRespuesta)
async def transcribir_audio(
    archivo_audio: UploadFile = File(...),
    session_id: Optional[str] = Form(None),
    current_user: User = Depends(get_current_user)
):
    """Transcribe audio usando Whisper de OpenAI."""
    try:
        session = None
        
        # Verificar sesi√≥n si se proporciona (pero no es obligatorio)
        if session_id:
            try:
                session = await obtener_sesion_audio(session_id, current_user.id)
                print(f"‚úÖ Sesi√≥n encontrada: {session_id}")
            except HTTPException as e:
                # Log el problema pero continuar sin sesi√≥n
                print(f"‚ö†Ô∏è Sesi√≥n no v√°lida {session_id}: {e.detail}")
                session = None
        else:
            print("‚ÑπÔ∏è Transcripci√≥n sin sesi√≥n")
        
        # Validar archivo
        if not archivo_audio.content_type.startswith('audio/'):
            raise HTTPException(status_code=400, detail="El archivo debe ser de audio")
        
        # Verificar tama√±o (max 25MB)
        contenido = await archivo_audio.read()
        if len(contenido) > 25 * 1024 * 1024:
            raise HTTPException(status_code=400, detail="El archivo es demasiado grande (m√°ximo 25MB)")
        
        print(f"üé§ Procesando audio: {len(contenido)} bytes, tipo: {archivo_audio.content_type}")
        
        # Crear archivo temporal
        with tempfile.NamedTemporaryFile(delete=False, suffix='.wav') as temp_file:
            temp_file.write(contenido)
            temp_path = temp_file.name
        
        try:
            # Usar servicio de audio con Whisper real
            audio_service = get_audio_service()
            resultado = await audio_service.procesar_audio_completo(contenido)
            
            if not resultado["success"]:
                raise HTTPException(status_code=400, detail=resultado.get("error", "Error procesando audio"))
            
            transcripcion = resultado["texto"]
            print(f"‚úÖ Transcripci√≥n exitosa: {transcripcion[:100]}...")
            
            # Si hay sesi√≥n v√°lida, guardar la transcripci√≥n como mensaje
            if session:
                try:
                    mensaje_data = {
                        "sesion_id": session['id'],
                        "contenido": f"[Audio transcrito] {transcripcion}",
                        "tipo": "user",
                        "timestamp": datetime.now().isoformat()
                    }
                    
                    supabase.table('chat_mensajes')\
                        .insert(mensaje_data)\
                        .execute()
                    
                    print(f"üíæ Mensaje guardado en sesi√≥n {session['id']}")
                except Exception as e:
                    print(f"‚ö†Ô∏è Error guardando mensaje: {e}")
                    # Continuar sin guardar
            
            return TranscripcionRespuesta(
                exito=True,
                texto_transcrito=transcripcion,
                duracion_audio=resultado.get("duracion", 0.0),
                idioma_detectado="es",
                confianza=0.95,
                timestamp=datetime.now().isoformat()
            )
            
        finally:
            # Limpiar archivo temporal
            os.unlink(temp_path)
            
    except HTTPException:
        # Re-lanzar errores HTTP espec√≠ficos
        raise
    except Exception as e:
        print(f"‚ùå Error inesperado transcribiendo audio: {str(e)}")
        raise HTTPException(status_code=500, detail=f"Error transcribiendo audio: {str(e)}")

@router.post("/mensaje-audio")
async def procesar_mensaje_audio(
    mensaje_audio: MensajeAudio,
    current_user: User = Depends(get_current_user)
):
    """Procesa un mensaje de audio transcrito."""
    try:
        session = await obtener_sesion_audio(mensaje_audio.session_id, current_user.id)
        
        # Guardar mensaje de audio
        mensaje_data = {
            "sesion_id": session['id'],
            "contenido": mensaje_audio.transcripcion,
            "tipo": "user",
            "timestamp": datetime.now().isoformat(),
            "metadata": {
                "es_audio": True,
                "duracion": mensaje_audio.duracion,
                "idioma": mensaje_audio.idioma
            }
        }
        
        supabase.table('chat_mensajes')\
            .insert(mensaje_data)\
            .execute()
        
        # TODO: Procesar mensaje con el sistema de chat inteligente
        # Por ahora, respuesta simple
        respuesta = f"He recibido tu mensaje de audio: {mensaje_audio.transcripcion[:100]}..."
        
        # Guardar respuesta del bot
        respuesta_data = {
            "sesion_id": session['id'],
            "contenido": respuesta,
            "tipo": "bot",
            "timestamp": datetime.now().isoformat(),
            "metadata": {
                "respuesta_a_audio": True
            }
        }
        
        supabase.table('chat_mensajes')\
            .insert(respuesta_data)\
            .execute()
        
        return {
            "success": True,
            "mensaje": "Mensaje de audio procesado",
            "respuesta": respuesta,
            "session_id": mensaje_audio.session_id
        }
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Error procesando mensaje de audio: {str(e)}")

@router.get("/audio-to-text/{session_id}")
async def obtener_transcripciones(
    session_id: str,
    current_user: User = Depends(get_current_user)
):
    """Obtiene todas las transcripciones de audio de una sesi√≥n."""
    try:
        session = await obtener_sesion_audio(session_id, current_user.id)
        
        # Obtener mensajes de audio de la sesi√≥n
        response = supabase.table('chat_mensajes')\
            .select('*')\
            .eq('sesion_id', session['id'])\
            .execute()
        
        mensajes = response.data or []
        
        # Filtrar mensajes de audio
        mensajes_audio = [
            m for m in mensajes 
            if m.get('metadata', {}).get('es_audio') or '[Audio transcrito]' in m.get('contenido', '')
        ]
        
        return {
            "success": True,
            "session_id": session_id,
            "transcripciones": mensajes_audio,
            "total": len(mensajes_audio)
        }
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Error obteniendo transcripciones: {str(e)}")

@router.post("/texto-a-audio")
async def texto_a_audio(
    solicitud: TextoAudio,
    current_user: User = Depends(get_current_user)
):
    """Convierte texto a audio usando s√≠ntesis de voz."""
    try:
        session = await obtener_sesion_audio(solicitud.session_id, current_user.id)
        
        # TODO: Implementar s√≠ntesis de voz con OpenAI TTS
        # Por ahora, simular generaci√≥n de audio
        
        # Simular archivo de audio generado
        audio_url = f"/api/audio/temp/{solicitud.session_id}_audio.mp3"
        
        return {
            "success": True,
            "audio_url": audio_url,
            "duracion": len(solicitud.texto) * 0.1,  # Simulado
            "formato": "mp3",
            "idioma": "es",
            "session_id": solicitud.session_id
        }
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Error generando audio: {str(e)}")

@router.get("/formatos-soportados")
async def obtener_formatos_audio():
    """Obtiene la lista de formatos de audio soportados."""
    formatos_soportados = {
        "formatos": [
            {
                "extension": ".mp3",
                "mime_type": "audio/mpeg",
                "descripcion": "MP3 - Formato m√°s com√∫n"
            },
            {
                "extension": ".wav",
                "mime_type": "audio/wav",
                "descripcion": "WAV - Alta calidad sin compresi√≥n"
            },
            {
                "extension": ".m4a",
                "mime_type": "audio/mp4",
                "descripcion": "M4A - Formato de Apple"
            },
            {
                "extension": ".ogg",
                "mime_type": "audio/ogg",
                "descripcion": "OGG - Formato libre"
            }
        ],
        "limitaciones": {
            "tama√±o_maximo": "25 MB",
            "duracion_maxima": "60 minutos",
            "idiomas_soportados": ["es-AR", "es-ES", "en-US"]
        },
        "recomendaciones": {
            "calidad": "16 kHz o superior",
            "formato_preferido": "WAV o M4A",
            "ambiente": "Grabaci√≥n en lugar silencioso para mejor precisi√≥n"
        }
    }
    
    return {
        "success": True,
        "formatos_audio": formatos_soportados
    }

# ===== ENDPOINT TEMPORAL DE DEBUG PARA AUDIO =====
@router.get("/debug-audio-status")
async def debug_audio_status():
    """Endpoint temporal para diagnosticar problemas de audio"""
    import os
    import tempfile
    
    diagnostico = {
        "timestamp": datetime.now().isoformat(),
        "environment": {
            "openai_api_key": "‚úÖ Configurada" if os.getenv("OPENAI_API_KEY") else "‚ùå No configurada",
            "temp_dir": tempfile.gettempdir(),
            "temp_dir_writable": None,
            "pydub_available": None,
            "ffmpeg_available": None
        },
        "dependencies": {},
        "audio_service": {},
        "temp_file_test": {},
        "whisper_test": "No ejecutado"
    }
    
    # Test 1: Directorio temporal
    try:
        with tempfile.NamedTemporaryFile(delete=True) as tmp:
            tmp.write(b"test")
            diagnostico["environment"]["temp_dir_writable"] = "‚úÖ Escribible"
    except Exception as e:
        diagnostico["environment"]["temp_dir_writable"] = f"‚ùå Error: {str(e)}"
    
    # Test 2: pydub
    try:
        from pydub import AudioSegment
        diagnostico["environment"]["pydub_available"] = "‚úÖ Disponible"
        diagnostico["dependencies"]["pydub"] = "‚úÖ OK"
    except ImportError as e:
        diagnostico["environment"]["pydub_available"] = f"‚ùå Error: {str(e)}"
        diagnostico["dependencies"]["pydub"] = f"‚ùå ImportError: {str(e)}"
    
    # Test 3: ffmpeg (usado por pydub)
    try:
        import subprocess
        result = subprocess.run(['ffmpeg', '-version'], capture_output=True, text=True, timeout=5)
        if result.returncode == 0:
            diagnostico["environment"]["ffmpeg_available"] = "‚úÖ Disponible"
        else:
            diagnostico["environment"]["ffmpeg_available"] = "‚ùå No funciona"
    except Exception as e:
        diagnostico["environment"]["ffmpeg_available"] = f"‚ùå Error: {str(e)}"
    
    # Test 4: AudioService
    try:
        from rag.audio_service import get_audio_service
        audio_service = get_audio_service()
        diagnostico["audio_service"]["creation"] = "‚úÖ Servicio creado exitosamente"
        diagnostico["audio_service"]["openai_client"] = "‚úÖ Cliente OpenAI inicializado"
    except Exception as e:
        diagnostico["audio_service"]["creation"] = f"‚ùå Error: {str(e)}"
    
    # Test 5: Archivo temporal de audio
    try:
        # Crear un archivo de audio muy b√°sico (WAV header m√≠nimo)
        wav_header = b'RIFF\x24\x00\x00\x00WAVEfmt \x10\x00\x00\x00\x01\x00\x01\x00\x40\x1f\x00\x00\x80\x3e\x00\x00\x02\x00\x10\x00data\x00\x00\x00\x00'
        
        with tempfile.NamedTemporaryFile(suffix='.wav', delete=False) as tmp:
            tmp.write(wav_header)
            temp_path = tmp.name
        
        # Verificar que se puede leer
        with open(temp_path, 'rb') as f:
            content = f.read()
            diagnostico["temp_file_test"]["size"] = len(content)
        
        # Limpiar
        os.unlink(temp_path)
        diagnostico["temp_file_test"]["status"] = "‚úÖ Archivo temporal creado y le√≠do exitosamente"
        
    except Exception as e:
        diagnostico["temp_file_test"]["status"] = f"‚ùå Error: {str(e)}"
    
    return {
        "debug_info": diagnostico,
        "instrucciones": [
            "Ejecuta este endpoint desde tu frontend:",
            "fetch('/api/audio/debug-audio-status').then(r => r.json()).then(console.log)",
            "O visita directamente: https://tu-app.railway.app/api/audio/debug-audio-status",
            "Comparte el resultado para diagnosticar el problema espec√≠fico"
        ]
    }

@router.post("/test-transcribir-simple")
async def test_transcribir_simple(
    archivo_audio: UploadFile = File(...),
    current_user: User = Depends(get_current_user)
):
    """Endpoint simplificado para testear transcripci√≥n sin complejidades"""
    logs = []
    
    try:
        logs.append("üéØ Iniciando test de transcripci√≥n simple")
        
        # Leer archivo
        contenido = await archivo_audio.read()
        logs.append(f"üìÅ Archivo le√≠do: {len(contenido)} bytes, tipo: {archivo_audio.content_type}")
        
        # Verificar OpenAI API Key
        import os
        api_key = os.getenv("OPENAI_API_KEY")
        if not api_key:
            raise Exception("OPENAI_API_KEY no configurada")
        logs.append("üîë OPENAI_API_KEY encontrada")
        
        # Crear archivo temporal con extensi√≥n correcta basada en content_type
        if 'webm' in archivo_audio.content_type:
            extension = '.webm'
        elif 'mp4' in archivo_audio.content_type:
            extension = '.mp4'
        elif 'wav' in archivo_audio.content_type:
            extension = '.wav'
        elif 'mp3' in archivo_audio.content_type:
            extension = '.mp3'
        else:
            extension = '.webm'  # Default
            
        logs.append(f"üéµ Extensi√≥n detectada: {extension}")
        
        with tempfile.NamedTemporaryFile(delete=False, suffix=extension) as temp_file:
            temp_file.write(contenido)
            temp_path = temp_file.name
            
        logs.append(f"üìÇ Archivo temporal creado: {temp_path}")
        
        try:
            # Llamar directamente a OpenAI Whisper
            from openai import OpenAI
            client = OpenAI(api_key=api_key)
            
            with open(temp_path, "rb") as audio_file:
                transcript = client.audio.transcriptions.create(
                    model="whisper-1",
                    file=audio_file,
                    language="es"
                )
            
            transcripcion = transcript.text.strip()
            logs.append(f"‚úÖ Transcripci√≥n exitosa: {len(transcripcion)} caracteres")
            
            return {
                "exito": True,
                "texto_transcrito": transcripcion,
                "logs": logs,
                "metadata": {
                    "archivo_size": len(contenido),
                    "archivo_tipo": archivo_audio.content_type,
                    "extension_usada": extension
                }
            }
            
        finally:
            # Limpiar
            if os.path.exists(temp_path):
                os.unlink(temp_path)
                logs.append("üóëÔ∏è Archivo temporal eliminado")
            
    except Exception as e:
        logs.append(f"‚ùå Error: {str(e)}")
        return {
            "exito": False,
            "error": str(e),
            "logs": logs
        } 